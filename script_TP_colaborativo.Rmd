---
title: "R Notebook"
output: html_notebook
---

# LIBRERIAS
```{r, echo=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(readxl)
library(sqldf)
library(lubridate)
library(dplyr)
library(sentimentr)
library(arules)
library(stringi)
library(stringr)
library(tm)
library(tau)
```

# CARGA DE DATOS  
```{r}
df_artist <- read.csv("data/df_artist_sin_duplicados.csv")
df_charts_raw <- read.csv("data/df_charts_sin_duplicados.csv")
df_audio_features_raw <- read.csv("data/audio_features_plano_sin_duplicados.csv")
df_lyrics <- read.csv("data/df_lyrics.csv")

```


## Corrección duplicados
```{r}
# DF listo para el join con chrats
df_audio_features <- df_audio_features_raw %>% 
  group_by(track_name, external_urls_spotify) %>% 
  mutate(artist_all = paste(artist_name, collapse = ",|,")) %>%
  ungroup() %>% 
  mutate(artist_key = sub(",|,.*", "", artist_all)) %>% 
  dplyr::select(artist_name, artist_all, artist_key, everything(.)) %>% 
  distinct(artist_key, external_urls_spotify, .keep_all = T) %>% 
  as.data.frame()
```

## Creacion `cant_markets`
```{r}
contar_market <- function(x){
q <- length(unlist(strsplit(x, split = ",")))
return (q)
  }
df_audio_features$cant_markets <- sapply(df_audio_features[,"markets_concat"], contar_market)
```


## Vectores de features
```{r}
#features var continuos
features_continuas <- c('acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness',   'tempo', 'valence', 'cant_markets')

#features var_ categóricas
features_categoricas <- c('explicit', 'key_name', 'mode_name', "key_mode")

```


## Imputacion de loudness


```{r}
fit <- lm(loudness~energy+acousticness, data=df_audio_features)

modelo <- fit$coefficients

df_audio_features$loudness_reg_imp <- df_audio_features$loudness

X <- df_audio_features[df_audio_features$loudness>0, c('energy', "acousticness")]

df_audio_features$loudness_reg_imp[df_audio_features$loudness>0] <- modelo[1]+modelo[2]*X[,1]+modelo[3]*X[,2]

summary(df_audio_features[,c("loudness", "loudness_reg_imp")])

summary(fit)

#graficos con loudness con imputacion
par(mfrow = c(2,1)) 
hist(df_audio_features[,'loudness_reg_imp'], main='loudness', xlab="")
#hist(sqrt(df_audio_features[,'loudness_reg_imp']), main= 'loudness_sqrt', xlab="")
boxplot(df_audio_features[,'loudness_reg_imp'], horizontal = T)
#boxplot(sqrt(df_audio_features[,'loudness_reg_imp']), horizontal = T)



```

# CHARTS: agregación de features
```{r}
#metrica de popularidad
df_charts <- df_charts_raw %>% 
  group_by(Artist, Track_Name) %>%
  dplyr:: summarise(semanas_sum = as.double(n()),
            streams_sum = (sum(Streams, na.rm = T)/10^6 ),
            streams_min = (min(Streams)/10^6 ),
            streams_max = (max(Streams)/10^6 ),
            streams_avg = (mean(Streams)/10^6),
            position_avg = mean(Position, na.rm = T),
            position_min = min(Position), 
            position_max = max(Position)) %>% 
  ungroup() %>% 
  mutate(popularidad = as.numeric(streams_sum*semanas_sum/position_avg) )

```

# RIGTH JOIN `audio_features` Y `charts`
```{r}
#Armamos un join para tener una tabla de charts con las caracteristicas de las canciones
# deberian quedar 22993 filas completas
join_audio_charts <- df_audio_features %>% 
  select("artist_name","artist_all","artist_key",
         "track_name", "external_urls_spotify", "album_name", "album_release_year",
         all_of(features_continuas), all_of(features_categoricas)) %>% 
  right_join( df_charts,# %>%
               by = c(
                 "track_name" = "Track_Name", 
                      "artist_key" ="Artist"))

#HAY CHARTS QUE NO TIENEN FEATURES. HAY QUE TENERLO EN CUENTA PARA EL ANÁLISIS
library(mice)
md.pattern(join_audio_charts, rotate.names = TRUE)

```



# HISTOGRAMAS Y BARPLOTS DE VARIABLES
```{r}

##histograma de las variables continuas de audio_features

for (i in features_continuas){

  hist(df_audio_features[,i], main = paste("Histograma de", i, "(all data)"), xlab = i)
  abline(v = mean(df_audio_features[,i], na.rm = TRUE) , col="red")
  abline(v = median(df_audio_features[,i], na.rm = TRUE) , col="blue")
  legend("topright", legend = c("Media", "Mediana"), col=c("red", "blue"), lty =1)

}

#divido los features por su distribución
features_continuas_media <- c('danceability', 'tempo', 'valence')

features_continuas_mediana <- c('acousticness', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'cant_markets')


##histograma de las variables continuas de charts
for (i in c(features_continuas)){

  hist(join_audio_charts[,i], main = paste("Histograma de", i,  "(charts)"), xlab = i)
  abline(v = mean(join_audio_charts[,i], na.rm = TRUE) , col="red")
  abline(v = median(join_audio_charts[,i], na.rm = TRUE) , col="blue")

}

#divido features de charts según su distribución
audio_charts_continuas_media <- c('duration_ms', 'valence')

audio_charts_continuas_mediana <- c('danceability', 'acousticness', 'tempo', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'cant_markets', "Streams")


##medidas resumen y barplots de las variables categoricas audio_features
for(i in features_categoricas){

  barplot(sort(table(df_audio_features[,i]),decreasing = T), las=2, 
          main = paste("Barplot de", i, "(all data)"))
  # pie(table(df_features_categoricos[,i]))
}



##medidas resumen y barplots de las variables categoricas join_audio_charts

for(i in features_categoricas){
  barplot(table(join_audio_charts[,i]), las=2,
          main = paste("Barplot de", i, "(charts)")
          )
  # pie(table(df_features_categoricos[,i]))
}

```



# SESGO DE VARIABLES 


## Boxplots Variables Numéricas sin filtrar outliers
```{r}
par(mfrow=c(4,3))
for (feature in features_continuas){
  boxplot(df_audio_features[,feature], las=2, horizontal=T, main=feature)
}
```

Con excepción de valence el resto de las features poseían cierto sesgo. Se decidió transformar las variables que mayor sesgo poseían: duration_ms, instrumentalness, liveness, speechiness como método de corregir la distribución y achicar la cantidad de outliers. La variable loudness_reg_imp no fue modificada debido a que al ser negativa 

## Transformaciones

### Transformación logarítmica
```{r}
# "danceability,tempo,valence,acousticness,duration_ms,energy,instrumentalness,liveness,speechiness,cant_markets"

#sesgos d las variables                                                   
sort(apply(df_audio_features[,features_continuas], MARGIN = 2, function(x){ (3* (mean(x,na.rm = T)-median(x, na.rm = T)))/sd(x, na.rm = T)} ))

variables_sesgo <- unlist(strsplit("acousticness,duration_ms,instrumentalness,liveness,speechiness,cant_markets,energy", ","))

df_sesgadas <- df_audio_features[,variables_sesgo]

logaritmo_ajustado = function(x,delta){
  if (x==0.0){
    return(log(0.00+delta, base = 10))
  }else{
    return(log(x, base = 10))
  }
}
delta <- 10^(-6)

df_sesgadas_log_adjust <- data.frame(apply(df_audio_features[,variables_sesgo], MARGIN = c(1,2), 
                                           function(x) logaritmo_ajustado(x,delta)))

ggplot(reshape::melt(df_sesgadas), aes(value))+
  geom_histogram()+
  facet_wrap(~variable)

ggplot(reshape::melt(df_sesgadas_log_adjust), aes(value))+
  geom_histogram()+
  facet_wrap(~variable)


####################################################
# names(df_sesgadas_log_adjust) <- paste(names(df_sesgadas), "_log", sep="")
# names(df_sesgadas_log_adjust) <- names(df_sesgadas)
# df_datos <- cbind(df_sesgadas, df_sesgadas_log_adjust)

a <- df_sesgadas
b <- df_sesgadas_log_adjust
names(b) <- paste(names(df_sesgadas), "_log", sep="")
merged <- cbind(a,b)

merged <- merged[, order(names(merged))]

round((
  apply(
  merged, MARGIN = 2, function(x){ (3* (mean(x,na.rm = T)-median(x, na.rm = T)))/sd(x, na.rm = T)}
        )
          ),2)

```


```{r}
#histogramas de vbles transformadas con logaritmo
# transformacion <- c('instrumentalness','loudness','liveness','speechiness', 'duration_ms')

par(mfrow=c(3,5))
for (feature in variables_sesgo){
  hist(df_audio_features[,feature], main=feature)
}

for (feature in variables_sesgo){
  hist(unlist(lapply(df_audio_features[,feature], function(x) logaritmo_ajustado(x,delta))), main=paste(feature,"log", sep="_"))
}
```
### Transformacion inversa raiz cuadrada

```{r}

inv_sqrt_ajustada = function(x, delta){
  if (x==0.0){
    return(1/sqrt(x+delta))
  }else{
    return(1/sqrt(x))
  }
}
delta <- 10^(-6)

par(mfrow=c(3,5))
for (feature in variables_sesgo){
  hist(df_audio_features[,feature], main=feature)
}

for (feature in variables_sesgo){
  hist(unlist(lapply(df_audio_features[,feature], function(x) inv_sqrt_ajustada(x,delta))), main=paste(feature,"inv_sqt", sep="_"))
}

df_sesgadas_inv_sqrt <- data.frame(apply(df_audio_features[,variables_sesgo], MARGIN = c(1,2), 
                                           function(x) inv_sqrt_ajustada(x,delta)))

```


```{r}
#nuevos sesgos con inversa raiz cuadrada
a <- df_sesgadas
b <- df_sesgadas_inv_sqrt
names(b) <- paste(names(df_sesgadas), "_invsqrt", sep="")
merged <- cbind(a,b)

merged <- merged[, order(names(merged))]

round((
  apply(
  merged, MARGIN = 2, function(x){ (3* (mean(x,na.rm = T)-median(x, na.rm = T)))/sd(x, na.rm = T)}
        )
          ),2)


b <- df_sesgadas_inv_sqrt[,c("cant_markets", "energy", "instrumentalness", "liveness" , "speechiness")]
names(b) <- paste(names(b), "_invsqrt", sep="")
ggplot(data=reshape::melt(b), aes(value))+
  geom_histogram(bins = 5)+facet_wrap(~variable, scales = "free")

```






## Discretización

```{r}

scale_vble <- function(x){
  (x - mean(x, na.rm = T))/sd(x, na.rm = T)
}

minmax


#join entre variables transformadas y resto features
audio_sin_sesgo <- df_audio_features %>% 
  select("artist_name", "artist_key",
         "track_name",
         all_of(features_continuas), all_of(features_categoricas)) %>%
  select(!variables_sesgo) 


#falta transformar df_charts !!!

join_audio_charts <- cbind(audio_sin_sesgo, df_sesgadas_log_adjust[,c("acousticness", "duration_ms")],
                           df_sesgadas_inv_sqrt[,c("instrumentalness", "cant_markets",
                                                   "energy", "liveness" , "speechiness")]) %>% 
  right_join( df_charts %>%
               select( "Track_Name", "Artist", 
                       "streams_avg", "position_avg",
                       "semanas_sum", "popularidad"),
               by = c("track_name" = "Track_Name", 
                      "artist_key" ="Artist")) %>% 
  select(-c("artist_key", "key_name", "explicit", "mode_name" ,"key_mode")) %>% 
  group_by(artist_name, track_name) %>%
  summarise_all( function(x) mean(x, na.rm= T))%>%
  ungroup() %>% 
  filter(!is.na(artist_name)) %>% 
  group_by(artist_name, track_name)# %>%
  # mutate_all(function(x) scales::rescale(x, to=c(0,1)))
  # mutate_all(function(x)  (x-min(x, na.rm = T)) / (max(x, na.rm = T)-min(x, na.rm = T)) ) 
  


```

```{r}
join_audio_charts %>% 
  gather(key = variable, value = valor, 3:ncol(.)) %>% 
  ggplot(aes(valor))+
  geom_histogram()+
  facet_wrap(~variable, scales = "free")
```




```{r}
join_audio_charts %>% 
  mutate_all(scale)
  

apply(X = x[,-c(1,2)], MARGIN = 2,  FUN =  function(x){ cut(x, quantile(x, robs = seq(0, 1, 0.25)),
                                                            label = c("Muy Alta", "Alta", "Media", "Baja")  )}  )


join_audio_charts %>% 
  ungroup() %>% 
  group_by(artist_name, track_name) %>% 
  mutate_all( function(x){ cut(x, quantile(x, probs = seq(0, 1, 0.25) ), labels = c("Muy Alta","Alta" ,"Media", "Baja") ) } )

###############

cut(join_audio_charts$danceability, quantile(join_audio_charts$danceability, 
                                             probs = seq(0, 1, 0.25) ),
    labels = c("Muy Alta","Alta" ,"Media", "Baja") )  

# Discretizaciones basadas en Quantile
# join_audio_charts$cat_danc = 
cut(join_audio_charts$danceability, breaks = c(1, 25, 100,200),#quantile(df_feat$position), 
    labels = c("Muy Alta","Media", "Baja")) #c("Muy Alta", "Alta","Media", "Baja"))


df_cat <-  join_audio_charts[, c("artist_name","track_name")]
cols <- names(join_audio_charts)[!names(join_audio_charts) %in% c("artist_name","track_name")]
df_num = join_audio_charts[,cols]




library(R.oo)
intToChar(65:(65+length(breaks)))
intToUtf8(65:78,multiple=TRUE)

for(i in seq_along(df_num) ){
  
  breaks =unique(quantile(df_num[[i]], probs = seq(0, 1, 0.25)))
  
  # label = intToChar(65:(65+length(breaks)))
  
  x <-   cut(df_num[[i]], breaks=breaks,
            # labels = label )
            labels  = c("Muy Alta","Alta" ,"Media", "Baja") )

  df_cat <-  cbind(df_cat, x ) 
  }

output <-list()  

####################
apply(df_num, 2, function(x){ cut(x, quantile(x, probs = seq(0, 1, 0.25) ),
                             # include.lowest=TRUE,
                labels = c("Muy Alta","Alta" ,"Media", "Baja") ) } )


for (i in seq_along(y)) {            
  output[[i]] <- cut(y[[i]], quantile(y[[i]] ),
            labels = c("Muy Alta","Alta" ,"Media", "Baja") )
}
output

```





### Z-Score de Variables que "tienden a la normal"
```{r}

################################

## FILTRAMOS OUTLIERS POR Z-SCORE para 'danceability', 'tempo', 'valence'

##############################

#z-score para variables que tienden a la normal
#filtro features numericos 

#divido los features por su distribución
features_continuas_media <- c('danceability', 'tempo', 'valence')
df_audio_features_zscore_media <- df_audio_features[,features_continuas_media]

#normalizo z score con las variables que tienden a la normal

zscore_cols <- c()
for(col in names(df_audio_features_zscore_media)){
  name_col <- paste('zscore_',col, sep = "")
  zscore_cols <- append(zscore_cols, name_col)
  media <-  mean(df_audio_features_zscore_media[,col])
  stdv <- sd(df_audio_features_zscore_media[,col])
  df_audio_features_zscore_media[,name_col] <- (df_audio_features_zscore_media[,col] - media)/stdv
  }

par(mfrow=c(1,length(zscore_cols)))
lapply(zscore_cols, function(col) boxplot(df_audio_features_zscore_media[,col],xlab=col))
```

### Analisis de Z-Score por variable
 
Danceability

```{r}
#variable: danceability

umbral_zscore <- 3
conditions <- (df_audio_features_zscore_media$zscore_danceability> umbral_zscore) | (df_audio_features_zscore_media$zscore_danceability< -1*umbral_zscore)
df_audio_features[conditions,] %>%
  select(album_name,artist_name, danceability ) %>%
  arrange(-danceability)
```

Tempo

```{r}
#variable: Tempo

umbral_zscore <- 3
conditions <- (df_audio_features_zscore_media$zscore_tempo> umbral_zscore) | (df_audio_features_zscore_media$zscore_tempo< -1*umbral_zscore)
df_audio_features[conditions,] %>%
  select(album_name,artist_name, tempo ) %>%
  arrange(-tempo)
```

Valence

```{r}
#variable: valence
umbral_zscore <- 3
conditions <- (df_audio_features_zscore_media$zscore_valence> umbral_zscore) | (df_audio_features_zscore_media$zscore_valence< -1*umbral_zscore)
df_audio_features[conditions,] %>%
  select(album_name,artist_name, valence ) %>%
  arrange(-valence)
```

### Z-Score Modificado de Variables Asimetricas

```{r}
################################

## FILTRAMOS OUTLIERS POR Z-SCORE MODIFICADO para 'acousticness', 'duration_ms', 'energy',  'instrumentalness', 'liveness', 'loudness', 'speechiness', 'cant_markets'

##############################

features_continuas_mediana <- c('acousticness', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'cant_markets')

df_audio_features_zscore_mediana <- df_audio_features[,features_continuas_mediana]



zscoremodif_cols <- c()
for(col in names(df_audio_features_zscore_mediana)){
  name_col <- paste('zscoremodif_',col, sep = "")
  zscoremodif_cols <- append(zscoremodif_cols, name_col)
  med = median(df_audio_features_zscore_mediana[,col], na.rm = T)
  MAD = median(abs(df_audio_features_zscore_mediana[,col] - med), na.rm = T)
  df_audio_features_zscore_mediana[, name_col] <- 0.6745 * (df_audio_features_zscore_mediana[,col] - med) / MAD
}


par(mfrow=c(4,2))
lapply(zscoremodif_cols, function(col) boxplot(df_audio_features_zscore_mediana[,col],xlab=col, horizontal = T))

```


Revisión Variable `Instrumentalness`
```{r}
instrumentalness <- c("instrumentalness", "zscoremodif_instrumentalness") 

x <- df_audio_features$instrumentalness

n_interv <- 10


intervalos <- round(seq(0,max(x),by=(max(x)-min(x))/n_interv),2)

labs <- c()
for (i in 1:n_interv){
lab <- paste(intervalos[i],intervalos[i+1], sep='\n')
labs <- append(labs, lab)
    
}

bins <- cut(x, n_interv, include.lowest = TRUE, labels = labs)

barplot(table(bins))

```

Hacemos K-means para poder discretizar la variable. 

```{r}
sse <- c()
for (k in 2:6){
  clusters <- kmeans(df_audio_features$instrumentalness,centers = k, iter.max = 10, nstart = k)
  sse <- append(sse, clusters$tot.withinss)
}

plot(2:6,sse, type = 'l', xlab='Cantidad de Clusters', ylab='Suma Error Cuadrático')

#k=3 
clusters3 <- kmeans(df_audio_features$instrumentalness,centers = 3, iter.max = 10, nstart = 3)

df_audio_features$clusters <- factor(clusters3$cluster)

lev <- levels(df_audio_features$clusters)

labs <- c()
for (i in lev){
  min <- min(df_audio_features$instrumentalness[df_audio_features$clusters==i])
  max <- max(df_audio_features$instrumentalness[df_audio_features$clusters==i])
  lab <- paste(min,max, sep=' - ')
  labs <- append(labs, lab)
}

labs

# barplot(table(factor(clusters3$cluster)), labels = labs)



```


#prueba igal de transformacion y test de normalidad
```{r}
join_audio_charts[1:5,"acousticness"]^2

library(nortest)

log10(df_chart_w_lyrics$acousticness)

for (i in features_continuas){
   x <- log10(df_chart_w_lyrics[,i])
   x <- shapiro.test(x)
   z <- x$p.value
  print(z)
  }


```



# LYRICS


## Filtro por idioma
```{r}
library(textcat)

df_lyrics <- read.csv("data/df_lyrics.csv") %>% 
  select(-X)

df_lyrics_unicas <- df_lyrics %>% 
  distinct(artist_name, track_name, lyrics)


#filtro de idioma
spa_lyrics = df_lyrics_unicas[textcat(df_lyrics_unicas$lyrics)=="spanish",]


en_lyrics = df_lyrics_unicas[textcat(df_lyrics_unicas$lyrics) %in% c("english", "scots"),]

```

```{r}
#chequeo cantidad de canciones por idioma
100*(nrow(en_lyrics) + nrow(spa_lyrics))/nrow(df_lyrics_unicas)

```

```{r}
# tabla contingencia de idiomas
idiomas = textcat(df_lyrics_unicas$lyrics)
sort(table(idiomas), decreasing = T)
```

### limpieza ingles
```{r}
#funciones
#funcion para corregir palabras
decontracted = function(txt){
  txt = gsub("ain't", "aint", txt)
  txt = gsub("wanna", "want to", txt)
  txt = gsub("gonna", "going to", txt)
  txt = gsub("won't", "will not", txt)
  txt = gsub("c'mon", "come on", txt)
  txt = gsub("let's", "let us", txt)
  txt = gsub("\\'s", " is", txt)
  txt = gsub("\\'t", " not", txt)
  txt = gsub("\\'ll", " will", txt)
  txt = gsub("\\'m", " am", txt)
  txt = gsub("\\'re", " are", txt)
  txt = gsub("\\'d", " had", txt)
  txt = gsub("\\'ve", " have", txt)
  txt = gsub("couldn", "could", txt)
  txt = gsub("don", "do", txt)
  txt = gsub("doesn", "does", txt)
  txt = gsub("isn", "is", txt)
  txt = gsub("mustn", "must", txt)
  txt = gsub("shouldn", "should", txt)
  txt = gsub("wasn", "was", txt)
  txt = gsub("\\'n", " and ", txt)
  txt = gsub("\\^'n'", " and ", txt)
  txt = gsub("\\^n'", " and ", txt)
  txt = gsub("\\'cause", " because", txt)
  txt = gsub("\\b'u\\b", " you", txt)
  txt = gsub("\\bu'\\b", " you ", txt)
  txt = gsub("\\bu\\b", "you", txt)
  txt = gsub("\\in'", "ing", txt)
  return(txt)
}


#Función para limpiar. 
text_cleaning = function(txt, language){
  txt = sub('^.+?\\[.*?\\]',"", txt) #ok
  txt = sub("More on Genius.*","", txt)
  txt = gsub('\\[.*?\\]', '', txt)
  txt = gsub("\\n"," ", txt)
  txt = gsub("[()]", " ", txt)
  txt = tolower(txt)
  #txt = gsub("\\W+\\b", " ", txt)
  txt = gsub("\\d", " ", txt)
  if(language == "en"){
    txt = decontracted(txt)
  }else if (language == "es"){
    txt = gsub("ñi","ni", txt)
    txt = gsub('ñ', 'ni', txt)
    txt = stri_trans_general(txt,"Latin-ASCII")
  }
  txt = gsub("\\W+\\b", " ", txt)
  return(txt)
}

#limpio las letras en ingles
en_lyrics$lyrics_cleaning = text_cleaning(en_lyrics$lyrics, language = "en")
spa_lyrics$lyrics_cleaning = text_cleaning(spa_lyrics$lyrics, language = "es")


write.csv(en_lyrics, "data/en_lyrics.csv", row.names = FALSE)


```

## STOPWORDS

### Inglés
```{r}

#El word_count_df se realiza con Python (ejecutar en_lyrics_word_coun)
word_counts_df <- read.csv("data/en_lyrics_word_count.csv")

```

```{r}
x <- 1:nrow(word_counts_df)
f <- word_counts_df$counts
plot(x,f, type="l",
          log = 'xy',
          col="blue",
          lwd=3,
          ylab = "Frecuencia Absoluta",
          xlab = "",
          main="Frecuencia de Palabras - Ley de Zipf")
```

```{r}
library(stopwords)

threshold <- 1000

x <- as.vector(word_counts_df[word_counts_df$counts>threshold,]$word)
not_remove_list = c("bitch","fuck","love","baby","nigga","feel", "girl", "shit")

top_stopwords <- setdiff(x, not_remove_list)

smart_stopwords <- stopwords("en", source = "smart")
my_eng_stopwords <- unique(append(smart_stopwords, top_stopwords))

```



### Español

```{r}
my_spa_stopwords <- unique(text_cleaning(stopwords("es", source = "stopwords-iso"), language = "es"))
```


###Borro Stopwords
```{r}
del_stopwords = function(txt, stopword_list){
  remove_regex = paste("\\b(", paste(my_eng_stopwords, collapse = "|"),")\\W", sep="")
  txt = gsub(remove_regex, " ", txt)
  txt = gsub("\\W+\\b", " ", txt)
  return(txt)
}

spa_lyrics$sin_stopwords <- del_stopwords(spa_lyrics$lyrics_cleaning, my_spa_stopwords)
en_lyrics$sin_stopwords <- del_stopwords(en_lyrics$lyrics_cleaning, my_eng_stopwords)

```



## DICCIONARIO DE MALAS PALABRAS

### Español
```{r}
#Diccionario español
malas_palabras_1 <- read_csv("data/malas_palabras.txt", 
    col_names = FALSE)

malas_palabras_2 <- read_csv("data/malas_palabras_translate.txt", 
    col_names = FALSE)

malas_palabras_3 <- read_csv("data/malas_palabras_wiki.txt", 
    col_names = FALSE) %>% 
  select(X1)

malas_palabras_4 <- read_csv("data/palabras_profanas_es.txt", 
                             col_names = FALSE)

malas_palabras <- rbind(malas_palabras_1, malas_palabras_2,
                        malas_palabras_3, malas_palabras_4)


#Hacer unique para eliminar las repetidas

malas_palabras$limpias = text_cleaning(malas_palabras$X1, language="es")
```

### Inglés
```{r}
#Genero lista de malas palabras
racist_words <- unique(tolower(lexicon::profanity_racist))

biglou <- read.csv("https://www.cs.cmu.edu/~biglou/resources/bad-words.txt", header=FALSE, col.names = c("words"))
```


## MATRIZ TERMINO DOCUMENTO
```{r}
####################################################################
####### Generación de la Matríz Término-Documento del corpus #######
####################################################################
corpus.pro2tdm <- function(corpus, ponderacion, n_terms){
  #corpus
  
  
  #matriz TD 
  dtm <- TermDocumentMatrix(corpus,
                            control = list(weighting = ponderacion))
  matriz_td <- as.matrix(dtm)
  
  
  # Calculamos la frecuencia de cada término en el corpus
  freq_term <- head(sort(rowSums(matriz_td),decreasing=TRUE), n_terms)
  
  #matriz transpuesta de los n_terms mas frecuentes
  matriz_nf <- t(matriz_td[sort(names(freq_term)), ])
  
  #pasaje a binario
  matriz_nf[matriz_nf>0] <- 1
  
  return(matriz_nf)
  
  }
  
corpus_eng = Corpus(VectorSource(enc2utf8(en_lyrics$lyrics)))
matriz <- corpus.pro2tdm(corpus = corpus_eng, ponderacion= "weightTf",n_terms= 150)

dim(matriz)

df_tm <- as.data.frame(matriz)
head(df_tm,2)

## Join matriz de palabras con artista y track
df_ly_feat <- cbind(df_lyrics_seleccionado[-c(3)], df_tm)

nrow(df_tm)
nrow(df_lyrics_seleccionado)
nrow(df_ly_feat)

filter <- !names(df_ly_feat) %in% c("artist_name", "track_name" )

df_ly_feat_ok <- df_ly_feat[, filter]
# df_ly_feat_ok = df_ly_feat_ok[, -(which(colSums(df_ly_feat_ok) == 0))]

# colSums(df_ly_feat_ok)

head(df_ly_feat_ok, 3)
head(df_ly_feat, 3)


df_ly_feat$id = 1:nrow(df_ly_feat)

df_melt <- reshape2::melt(data = df_ly_feat[,3:ncol(df_ly_feat)], id.vars = c("id"))  %>%
  arrange(id)

df_melt <- df_melt[df_melt$value != 0,]

df_melt_txt <- df_melt[df_melt$value == 1,]
df_melt_cat <- df_melt[df_melt$value != 1,]

head(df_melt_txt )
dim(df_melt_txt )

#denomino a los términos profanos
df_melt_txt <- df_melt_txt %>% 
  mutate(variable = case_when(as.character(variable) %in% biglou$words ~
                                paste0("PROFANE_", as.character(variable)),
                              as.character(variable) %in%  racist_words ~
                                paste0("RACIST_", as.character(variable)),
                              T ~ paste0("TERM_", as.character(variable))
                              )  
         )

df_melt_txt %>% filter(startsWith(variable, "PROF"))


# df_melt_txt[df_melt_txt$variable %in% biglou$words,]


df_melt_txt_to_ruls <- df_melt_txt[, -c(3)]
names(df_melt_txt_to_ruls) <- c("id", "item")

write.table(df_melt_txt_to_ruls, file="data/transaccions_lyrics_features.txt", row.names = F)

# Reglas
# chequear nan's
lyrics_trans <- read.transactions("data/transaccions_lyrics_features.txt", format = "single", cols = c(1,2))

arules::inspect(head(lyrics_trans, 3))

summary(lyrics_trans)
reglas <- apriori(lyrics_trans, parameter = list(support=0.1,
                    confidence = 0.5, target  = "rules"  ))

reglas_sub <- subset(reglas, subset = rhs %pin% "PROF_")
arules::inspect(head(sort(reglas_sub, by = "lift", decreasing = T),5))

```


## Carga de Igal (UNIFICAR)
```{r}
df_lyrics_unicas <- df_lyrics %>% distinct(artist_name, track_name, lyrics)
nrow(df_lyrics_unicas)

df_chart_w_lyrics <- merge(join_audio_charts, df_lyrics_unicas, by.x = c("artist_name","track_name"), by.y= c("artist_name","track_name"), all.x=TRUE, all.y = FALSE)

df_chart_w_lyrics <- df_chart_w_lyrics[!is.na(df_chart_w_lyrics$lyrics),]

```


## Explicit

### contar malas palabras (Parte de Igal: UNIFICAR)
```{r}

bad_words <- c()
bad_words <- append(bad_words, unique(tolower(lexicon::profanity_zac_anger)))
bad_words <- append(bad_words, unique(tolower(lexicon::profanity_alvarez)))
bad_words <- append(bad_words, unique(tolower(lexicon::profanity_arr_bad)))
bad_words <- append(bad_words, unique(tolower(lexicon::profanity_racist)))
bad_words <- append(bad_words, unique(tolower(lexicon::profanity_banned)))

bad_words <- unique(bad_words)


contar_bad_words <- function(x){
  x <- profanity(x,profanity_list = bad_words)
  q <- sum(x$profanity_count)
  return (q)
  }
df_chart_w_lyrics$cant_bad_words <- sapply(df_chart_w_lyrics[,"lyrics"], contar_bad_words)


df_chart_w_lyrics_only_explicit <- df_chart_w_lyrics[df_chart_w_lyrics$explicit==TRUE & df_chart_w_lyrics$cant_bad_words > 0, ]

hist(df_chart_w_lyrics_only_explicit$cant_bad_words)


#creo vars categóricas
df_chart_w_lyrics_only_explicit$nivel_puteada <- cut(df_chart_w_lyrics_only_explicit$cant_bad_words, breaks = c(0,10,20,50,Inf), labels=c("bajo","poco","alto","muy_alto"))

df_chart_w_lyrics_only_explicit$nivel_ranking <- cut(df_chart_w_lyrics_only_explicit$position_avg, breaks = c(1,100,Inf), labels=c("1a100","100a200"))

df_chart_w_lyrics_only_explicit$nivel_popularidad <- cut(sqrt(df_chart_w_lyrics_only_explicit$cant_bad_words), breaks = c(0,10,20,50,Inf), labels=c("bajo","poco","alto","muy_alto"))

transactions <- as(as.data.frame(apply(df_chart_w_lyrics_only_explicit, 2, as.factor)), "transactions")
rules = apriori(transactions, parameter=list(target="rules", confidence=0.25, support=0.1))
rules.sub <- subset(rules, subset = lhs %pin% "nivel_puteada" & rhs %pin% "nivel_ranking")
inspect(head(sort(rules.sub, by = "lift", decreasing = TRUE),10))

# discretizacion continuas y seleccion de variables
# identificar palabras explít

```



```{r}

```





# LIMPIO HASTA ACA

# Preguntas de investigacion

## Patron Comun Canciones del Chart
¿Qué características tienen las canciones que están en el chart? ¿Cual es el patrón comun que tienen las canciones más escuchadas? (ver dispersiones, media, grafico comparativo)
```{r}


#funcion para escalar variable


```
```{r}
#anti_join
anti_join_audio_charts <- df_audio_features %>% 
  select("artist_name","artist_all", "artist_key",
         "track_name", "external_urls_spotify", "album_name", "album_release_year",
         all_of(features_continuas), all_of(features_categoricas)) %>% 
  anti_join( df_charts %>%
               select( "Track_Name", "Artist", "URL"),
               by = c("external_urls_spotify" ="URL",
                      "artist_key" ="Artist"  ))
               # by = c("track_name" = "Track_Name"))


anti_join_audio_charts_complete <- na.omit(anti_join_audio_charts)
anti_join_audio_charts_complete_scale <- anti_join_audio_charts_complete %>% 
  distinct() %>% 
  select(features_continuas)  %>% 
  mutate_all(scale_vble)
nrow(anti_join_audio_charts_complete_scale)

```

## Qué temas perduran mucho en el ranking

### Artistas que mas aparecen en el chart
```{r}
join_audio_charts %>% 
  group_by(artist_name) %>% 
  dplyr::summarise(n = n()) %>% 
  arrange(-n)
```

### Tracks que mas aparecen en el chart
```{r}
join_audio_charts %>% 
  group_by(track_name, artist_name,external_urls_spotify) %>% 
  dplyr::summarise(n = n()) %>% 
  arrange(-n) %>% 
  select(track_name, n, everything(.))

```


# ¿Cuánto tiempo están en un chart? 

```{r}
# cantidad de semanas que estuvieron en el chart

df_charts %>% 
  mutate(week_start=as.Date(week_start),
         week_end = as.Date(week_end),
         week_year = (year(week_start))) %>%
  arrange(Artist, Track_Name) %>% 
  group_by(Artist, Track_Name, URL) %>% 
 dplyr:: summarise( day_in = min(week_start),
             year_in = year(day_in),
             day_max = max(week_end),
             year_max = year(day_max),
             duracion_chart_dias = day_max-day_in,
             duracion_chart_anio = year_max - year_in) %>% 
  arrange(Artist)

```

